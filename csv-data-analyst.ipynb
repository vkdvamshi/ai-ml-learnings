{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e757f4",
   "metadata": {},
   "source": [
    "CSV Data Analyst\n",
    "LangChain + Pandas\n",
    "ðŸŽ“ Essentials\n",
    "Talk to your spreadsheets in plain English\n",
    "\n",
    "Upload any CSV file and ask questions like \"What's the average sales by region?\" or \"Show me the top 10 customers.\" Get answers and charts instantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 20:18:20.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.534 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.535 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.537 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.538 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.538 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-10 20:18:20.539 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain_classic.llms import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key as an environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "    \n",
    "@st.cache_resource\n",
    "def create_vector_store(dataframe):\n",
    "    # Convert DataFrame to documents for RAG\n",
    "    loader = DataFrameLoader(dataframe, page_content_column=dataframe.columns[0]) # Use first column as content for simplicity\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Create embeddings and store in vector db\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = Chroma.from_documents(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "st.title(\"CSV to SQL/Text Query Bot\")\n",
    "uploaded_file = st.file_uploader(\"Upload a CSV file\", type=[\"csv\"])\n",
    "# if uploaded_file is not None:\n",
    "#     df = pd.read_csv(uploaded_file)\n",
    "#     st.write(\"Data Preview:\", df.head())\n",
    "#     vector_store = create_vector_store(df)\n",
    "#     llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "#     qa_chain = RetrievalQA.from_chain_type(\n",
    "#         llm, \n",
    "#         chain_type=\"stuff\", \n",
    "#         retriever=vector_store.as_retriever()\n",
    "#     )\n",
    "\n",
    "\n",
    "# question = st.text_input(\"Ask a question about the data:\")\n",
    "# if question:\n",
    "#         try:\n",
    "#             response = qa_chain.invoke({\"query\": question})\n",
    "#             st.success(response[\"result\"])\n",
    "#         except Exception as e:\n",
    "#             st.error(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
